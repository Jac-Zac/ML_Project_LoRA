{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5443aea-e1ce-4667-9a83-ff6a7482b75f",
   "metadata": {},
   "source": [
    "# Lora finetuning\n",
    "> Example of finetuning lora\n",
    "\n",
    "In the following notebook we are going to use my custom implementation of LoRA to fine-tune a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28726d2-8a8f-46f8-b734-54c9d28e77a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780e6273-af80-4264-a68f-82a4ed80e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tinygrad import Tensor, nn\n",
    "import copy\n",
    "\n",
    "# from extra.training import evaluate, train\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98afb72-3e0c-4c52-bbc5-d42e8f700afb",
   "metadata": {},
   "source": [
    "##### Importing custom LoRA library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f58925-8a6c-4676-abe6-47004e8cb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the path of the current working directory\n",
    "current_dir = os.path.abspath(os.getcwd())\n",
    "\n",
    "# Get the path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import the LoRA module\n",
    "from lora_tinygrad import LoRA\n",
    "\n",
    "# Now you can import the DoRA module\n",
    "from dora_tinygrad import DoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb8ceef-b83a-4ed9-ace0-88c14bcf5b8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Define a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b591ab9a-2058-4d2c-a111-e69ae2932ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyNet:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Linear(784, 784 * 3, bias=False)\n",
    "        self.l2 = nn.Linear(784 * 3, 784, bias=False)\n",
    "        self.l3 = nn.Linear(784, 128, bias=False)\n",
    "        self.l4 = nn.Linear(128, 10, bias=False)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.l1(x).leakyrelu()\n",
    "        x = self.l2(x).leakyrelu()\n",
    "        x = self.l3(x).leakyrelu()\n",
    "        x = self.l4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab64643-011b-4daf-862e-6cf6e4bd13a1",
   "metadata": {},
   "source": [
    "## Model pre-training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e2ddd-de04-4d69-ade5-6e1fce547a7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Hyperparameters & Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceae125-1350-47f8-81b3-4a49751ba15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochss = 3\n",
    "BS = 128\n",
    "n_outputs = 10\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = fetch_fashion_mnist()\n",
    "steps = len(X_train) // BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73467d72-f067-4ccd-8d4f-65a5aebb7100",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Defining the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0d7a60-f675-419a-823c-2fed4c22992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = TinyNet()\n",
    "\n",
    "# Define loss function\n",
    "lossfn = Tensor.sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a5359-c365-4589-9d3e-7af64429b226",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Traning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fa856c-18e6-4462-bcb1-69bd52520c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.33 accuracy 0.88: 100%|████████████████████████████████| 468/468 [00:03<00:00, 123.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 258.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.834200\n",
      "reducing lr to 0.0008333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.35 accuracy 0.88: 100%|████████████████████████████████| 468/468 [00:03<00:00, 137.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 339.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.854100\n",
      "reducing lr to 0.0006944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.26 accuracy 0.91: 100%|████████████████████████████████| 468/468 [00:03<00:00, 140.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 253.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.852600\n",
      "reducing lr to 0.0005787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-training the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(nn.state.get_parameters(model), lr=lr)\n",
    "    train(model, X_train, Y_train, optimizer, lossfn=lossfn, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(model, X_test, Y_test, return_predict=True)\n",
    "    lr /= 1.2\n",
    "    print(f\"reducing lr to {lr:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d981a-71f8-4a27-8e9f-a16ea7a6edda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get mislabeled predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62000b49-7f87-4702-9b40-35701ef618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "worst_class = max(mislabeled_counts, key=lambda k: mislabeled_counts[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d36961-040d-4df0-b34d-b82787b5cd68",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "\n",
    "Let's start by craeting a dataset for the finetuning on the worst examples to see if there is actually some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd49c4d-794e-4e87-b4e1-bda2ee0c1ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 192\n",
      "Class 1: Missing 61\n",
      "Class 2: Missing 238\n",
      "Class 3: Missing 74\n",
      "Class 4: Missing 391\n",
      "Class 5: Missing 28\n",
      "Class 6: Missing 309\n",
      "Class 7: Missing 64\n",
      "Class 8: Missing 62\n",
      "Class 9: Missing 55\n",
      "Fine-tuning the worst class, 4..\n"
     ]
    }
   ],
   "source": [
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"Fine-tuning the worst class, {worst_class}..\")\n",
    "lrs = 1e-5\n",
    "epochss = 1\n",
    "BS = 64\n",
    "\n",
    "# Get a mixture which is mostly filled with the worst class\n",
    "X_train, Y_train = mix_old_and_new_data(X_train, Y_train, worst_class, ratio = 0.3)\n",
    "steps = len(X_train) // BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce446f4-0cac-4f7a-aa13-c3df86a7b1c8",
   "metadata": {},
   "source": [
    "### Fine-tuning without Lora (full fine-tuning)\n",
    "\n",
    "Let's first do a full finetuning of the model to then compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457a8e7c-bb56-4010-97f8-b7f665d37b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.29 accuracy 0.91: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 147.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 305.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.858800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a copy of the model\n",
    "model_full_finetuning = copy.deepcopy(model) \n",
    "\n",
    "# Finetuning the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(nn.state.get_parameters(model_full_finetuning), lr=lr)\n",
    "    # Default loss function is sparse_categorical_crossentropy\n",
    "    train(model_full_finetuning, X_train, Y_train, optimizer, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(model_full_finetuning, X_test, Y_test, return_predict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72ffac-e39e-4f5e-a6ca-21246c021d2f",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c640f47-99da-45c4-9fc5-7426daaf5ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 171\n",
      "Class 1: Missing 44\n",
      "Class 2: Missing 319\n",
      "Class 3: Missing 77\n",
      "Class 4: Missing 117\n",
      "Class 5: Missing 78\n",
      "Class 6: Missing 474\n",
      "Class 7: Missing 61\n",
      "Class 8: Missing 32\n",
      "Class 9: Missing 39\n",
      "New worst class: 6\n"
     ]
    }
   ],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"New worst class: {max(mislabeled_counts, key=lambda k: mislabeled_counts[k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f874f5c-a96e-4269-bed8-78aeaf1409e8",
   "metadata": {},
   "source": [
    "### Fine-tuning with LoRA\n",
    "\n",
    "Now let's do the LoRA finetuning on the other same data with a rank of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed45b782-d8be-4ec5-a09e-c2b2ba7b4463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.56 accuracy 0.64: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 172.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 120.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.576100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the Lora model from the original model without modifying the original one\n",
    "lora_model = LoRA.from_module(model, rank=64, inplace=False)\n",
    "\n",
    "# Pre-training the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(lora_model.parameters(), lr=lr)\n",
    "    # Default loss function is sparse_categorical_crossentropy\n",
    "    train(lora_model, X_train, Y_train, optimizer, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(lora_model, X_test, Y_test, return_predict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05749ec-faf7-42fe-aa97-ee21bf07df95",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8904d40c-b096-47cc-9509-9cf9962fac41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 852\n",
      "Class 1: Missing 75\n",
      "Class 2: Missing 671\n",
      "Class 3: Missing 251\n",
      "Class 4: Missing 208\n",
      "Class 5: Missing 401\n",
      "Class 6: Missing 938\n",
      "Class 7: Missing 335\n",
      "Class 8: Missing 446\n",
      "Class 9: Missing 62\n",
      "New worst class: 6\n"
     ]
    }
   ],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"New worst class: {max(mislabeled_counts, key=lambda k: mislabeled_counts[k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a1027-7eab-4eb8-86cb-29e2798ae8b4",
   "metadata": {},
   "source": [
    "#### Show the parameters we trained in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5b1ec5-df31-4188-8010-4b1e25bb5e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_parameters = 3789568\n",
      "lora_parameters = 468608\n",
      "Percentage of parameters we update: 12.37%\n"
     ]
    }
   ],
   "source": [
    "original_parameters = sum(p.numel() for p in nn.state.get_parameters(model_full_finetuning))\n",
    "lora_parameters = sum(p.numel() for p in lora_model.parameters())\n",
    "\n",
    "print(f\"{original_parameters = }\")\n",
    "print(f\"{lora_parameters = }\")\n",
    "print(f\"Percentage of parameters we update: {(lora_parameters / original_parameters) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b4ec5-94c3-46c3-92fc-619e4a0d6dbe",
   "metadata": {},
   "source": [
    "### Fine-tuning with DoRA\n",
    "\n",
    "Now let's do the DoRA finetuning on the other same data with a rank of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c508230-5cf8-4a57-84d8-1ce429fc2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 1.95 accuracy 0.66: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 182.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 129.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.691000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the Lora model from the original model without modifying the original one\n",
    "dora_model = DoRA.from_module(model, rank=64, inplace=False)\n",
    "\n",
    "# Pre-training the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(dora_model.parameters(), lr=lr)\n",
    "    # Default loss function is sparse_categorical_crossentropy\n",
    "    train(dora_model, X_train, Y_train, optimizer, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(dora_model, X_test, Y_test, return_predict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bb409-ceac-41ca-8c0d-8e9e5a204cc6",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7657401a-08b9-44f7-8bab-b1743b819f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 364\n",
      "Class 1: Missing 88\n",
      "Class 2: Missing 401\n",
      "Class 3: Missing 136\n",
      "Class 4: Missing 153\n",
      "Class 5: Missing 548\n",
      "Class 6: Missing 672\n",
      "Class 7: Missing 409\n",
      "Class 8: Missing 49\n",
      "Class 9: Missing 270\n",
      "New worst class: 6\n"
     ]
    }
   ],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"New worst class: {max(mislabeled_counts, key=lambda k: mislabeled_counts[k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a66b42-ef3a-4f31-9d23-e2dbd5d3a3a7",
   "metadata": {},
   "source": [
    "#### Show the parameters we trained in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07184b27-06eb-4417-b78c-697999cfa09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_parameters = 3789568\n",
      "dora_parameters = 471882\n",
      "Percentage of parameters we update: 12.45%\n"
     ]
    }
   ],
   "source": [
    "original_parameters = sum(p.numel() for p in nn.state.get_parameters(model_full_finetuning))\n",
    "dora_parameters = sum(p.numel() for p in dora_model.parameters())\n",
    "\n",
    "print(f\"{original_parameters = }\")\n",
    "print(f\"{dora_parameters = }\")\n",
    "print(f\"Percentage of parameters we update: {(dora_parameters / original_parameters) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2592d-bd7c-4ad2-8436-fb296c9b1c20",
   "metadata": {},
   "source": [
    "## Other functionalities\n",
    "\n",
    "In the following section we will test some other functionalities I implemented in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae80bcd-d545-4d50-890a-582bfc5176e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything works as expected\n"
     ]
    }
   ],
   "source": [
    "# Getting a random example to test the model\n",
    "x = Tensor.randn(1, 28, 28).reshape(-1)\n",
    "\n",
    "# Assert if the values are not all the same and thus I have done something\n",
    "assert not np.allclose(model(x).numpy(), lora_model(x).numpy()), \"The outputs are too close!\"\n",
    "\n",
    "# Disable the lora parameters\n",
    "lora_model.disable_lora()\n",
    "\n",
    "# Assert if the values are the same and thus I haven't changed the original model\n",
    "assert np.allclose(model(x).numpy(), lora_model(x).numpy()), \"The outputs are too close!\"\n",
    "\n",
    "# Showcase that lora can be re-enabled\n",
    "lora_model.enable_lora()\n",
    "\n",
    "\n",
    "# Merge lora into the original weights not inplace\n",
    "new_model = lora_model.merge_lora(inplace=False)\n",
    "\n",
    "assert np.allclose(new_model(x).numpy(), lora_model(x).numpy()), \"The outputs are too close!\"\n",
    "\n",
    "# NOTE: new_model has the same type as the original model! Inference is just as fast as in the original model.\n",
    "assert isinstance(new_model, TinyNet)\n",
    "\n",
    "print(\"Everything works as expected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
