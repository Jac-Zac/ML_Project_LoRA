{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5443aea-e1ce-4667-9a83-ff6a7482b75f",
   "metadata": {},
   "source": [
    "# Lora finetuning\n",
    "> Example of finetuning lora\n",
    "\n",
    "In the following notebook we are going to use my custom implementation of LoRA to fine-tune a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28726d2-8a8f-46f8-b734-54c9d28e77a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780e6273-af80-4264-a68f-82a4ed80e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tinygrad import Tensor, nn\n",
    "import copy\n",
    "\n",
    "# from extra.training import evaluate, train\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98afb72-3e0c-4c52-bbc5-d42e8f700afb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Importing custom LoRA library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f58925-8a6c-4676-abe6-47004e8cb2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import the LoRA module\n",
    "from lora_tinygrad import LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb8ceef-b83a-4ed9-ace0-88c14bcf5b8a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Define a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b591ab9a-2058-4d2c-a111-e69ae2932ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyNet:\n",
    "    def __init__(self):\n",
    "        self.l1 = nn.Linear(784, 784 * 3, bias=False)\n",
    "        self.l2 = nn.Linear(784 * 3, 784, bias=False)\n",
    "        self.l3 = nn.Linear(784, 128, bias=False)\n",
    "        self.l4 = nn.Linear(128, 10, bias=False)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.l1(x).leakyrelu()\n",
    "        x = self.l2(x).leakyrelu()\n",
    "        x = self.l3(x).leakyrelu()\n",
    "        x = self.l4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab64643-011b-4daf-862e-6cf6e4bd13a1",
   "metadata": {},
   "source": [
    "## Model pre-training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e2ddd-de04-4d69-ade5-6e1fce547a7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Hyperparameters & Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceae125-1350-47f8-81b3-4a49751ba15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochss = 3\n",
    "BS = 128\n",
    "n_outputs = 10\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = fetch_fashion_mnist()\n",
    "steps = len(X_train) // BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73467d72-f067-4ccd-8d4f-65a5aebb7100",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Defining the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0d7a60-f675-419a-823c-2fed4c22992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = TinyNet()\n",
    "\n",
    "# Define loss function\n",
    "lossfn = Tensor.sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a5359-c365-4589-9d3e-7af64429b226",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Traning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fa856c-18e6-4462-bcb1-69bd52520c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.41 accuracy 0.84: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:04<00:00, 96.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 237.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.853900\n",
      "reducing lr to 0.0008333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.37 accuracy 0.86: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:04<00:00, 106.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 179.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.854300\n",
      "reducing lr to 0.0006944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.28 accuracy 0.88: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 468/468 [00:04<00:00, 107.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 183.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.865500\n",
      "reducing lr to 0.0005787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-training the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(nn.state.get_parameters(model), lr=lr)\n",
    "    train(model, X_train, Y_train, optimizer, lossfn=lossfn, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(model, X_test, Y_test, return_predict=True)\n",
    "    lr /= 1.2\n",
    "    print(f\"reducing lr to {lr:.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d981a-71f8-4a27-8e9f-a16ea7a6edda",
   "metadata": {},
   "source": [
    "#### Get mislabeled predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62000b49-7f87-4702-9b40-35701ef618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "worst_class = max(mislabeled_counts, key=lambda k: mislabeled_counts[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d36961-040d-4df0-b34d-b82787b5cd68",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "\n",
    "Let's start by craeting a dataset for the finetuning on the worst examples to see if there is actually some improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd49c4d-794e-4e87-b4e1-bda2ee0c1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 196\n",
      "Class 1: Missing 25\n",
      "Class 2: Missing 224\n",
      "Class 3: Missing 75\n",
      "Class 4: Missing 309\n",
      "Class 5: Missing 62\n",
      "Class 6: Missing 299\n",
      "Class 7: Missing 66\n",
      "Class 8: Missing 37\n",
      "Class 9: Missing 52\n",
      "Fine-tuning the worst class, 4..\n"
     ]
    }
   ],
   "source": [
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"Fine-tuning the worst class, {worst_class}..\")\n",
    "lrs = 1e-5\n",
    "epochss = 1\n",
    "BS = 64\n",
    "\n",
    "# Get a mixture which is mostly filled with the worst class\n",
    "X_train, Y_train = mix_old_and_new_data(X_train, Y_train, worst_class, ratio = 0.3)\n",
    "steps = len(X_train) // BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce446f4-0cac-4f7a-aa13-c3df86a7b1c8",
   "metadata": {},
   "source": [
    "### Fine-tuning without Lora\n",
    "\n",
    "Let's first do a full finetuning of the model to then compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "457a8e7c-bb56-4010-97f8-b7f665d37b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.28 accuracy 0.92: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [00:03<00:00, 118.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 175.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.840100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a copy of the model\n",
    "model_full_finetuning = copy.deepcopy(model) \n",
    "\n",
    "# Finetuning the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(nn.state.get_parameters(model_full_finetuning), lr=lr)\n",
    "    # Default loss function is sparse_categorical_crossentropy\n",
    "    train(model_full_finetuning, X_train, Y_train, optimizer, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(model_full_finetuning, X_test, Y_test, return_predict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72ffac-e39e-4f5e-a6ca-21246c021d2f",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c640f47-99da-45c4-9fc5-7426daaf5ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 403\n",
      "Class 1: Missing 44\n",
      "Class 2: Missing 396\n",
      "Class 3: Missing 172\n",
      "Class 4: Missing 63\n",
      "Class 5: Missing 53\n",
      "Class 6: Missing 334\n",
      "Class 7: Missing 75\n",
      "Class 8: Missing 25\n",
      "Class 9: Missing 34\n",
      "New worst class: 0\n"
     ]
    }
   ],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "print(f\"New worst class: {max(mislabeled_counts, key=lambda k: mislabeled_counts[k])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2306ba-4a8b-4bb9-b694-0af7865123ad",
   "metadata": {},
   "source": [
    "### Fine-tuning with Lora\n",
    "\n",
    "Now let's do the Lora finetuning on the other same data with a rank of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed45b782-d8be-4ec5-a09e-c2b2ba7b4463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.30 accuracy 0.89: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [00:02<00:00, 144.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 118.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy is 0.862400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting the Lora model from the original model without modifying the original one\n",
    "lora_model = LoRA.from_module(model, rank=64, inplace=False)\n",
    "\n",
    "# Pre-training the model\n",
    "for _ in range(epochss):\n",
    "    optimizer = nn.optim.Adam(lora_model.parameters(), lr=lr)\n",
    "    # Default loss function is sparse_categorical_crossentropy\n",
    "    train(lora_model, X_train, Y_train, optimizer, steps=steps, BS=BS)\n",
    "    accuracy, Y_test_pred = evaluate(lora_model, X_test, Y_test, return_predict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c86e00-f2f8-49fe-9a7e-bbe707c3668b",
   "metadata": {},
   "source": [
    "#### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8904d40c-b096-47cc-9509-9cf9962fac41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Missing 178\n",
      "Class 1: Missing 34\n",
      "Class 2: Missing 313\n",
      "Class 3: Missing 127\n",
      "Class 4: Missing 94\n",
      "Class 5: Missing 51\n",
      "Class 6: Missing 449\n",
      "Class 7: Missing 54\n",
      "Class 8: Missing 30\n",
      "Class 9: Missing 46\n"
     ]
    }
   ],
   "source": [
    "mislabeled_counts = get_mislabeled_counts(Y_test, Y_test_pred, n_output=n_outputs)\n",
    "pretty_print_mislabeled_counts(mislabeled_counts)\n",
    "worst_class = max(mislabeled_counts, key=lambda k: mislabeled_counts[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef5189-90b4-4928-be3a-4bcea22c9708",
   "metadata": {},
   "source": [
    "#### Show the parameters we trained in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5b1ec5-df31-4188-8010-4b1e25bb5e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_parameters = 3789568\n",
      "lora_parameters = 468608\n",
      "Percentage of parameters we update: 12.37%\n"
     ]
    }
   ],
   "source": [
    "original_parameters = sum(p.numel() for p in nn.state.get_parameters(model_full_finetuning))\n",
    "lora_parameters = sum(p.numel() for p in lora_model.parameters())\n",
    "\n",
    "print(f\"{original_parameters = }\")\n",
    "print(f\"{lora_parameters = }\")\n",
    "print(f\"Percentage of parameters we update: {(lora_parameters / original_parameters) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f2592d-bd7c-4ad2-8436-fb296c9b1c20",
   "metadata": {},
   "source": [
    "## Other functionalities\n",
    "\n",
    "In the following section we will test some other functionalities I implemented in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae80bcd-d545-4d50-890a-582bfc5176e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything works as expected\n"
     ]
    }
   ],
   "source": [
    "# Getting a random example to test the model\n",
    "x = Tensor.randn(1, 28, 28).reshape(-1)\n",
    "\n",
    "# Assert if the values are not all the same and thus I have done something\n",
    "assert not np.allclose(model(x).numpy(), lora_model(x).numpy()), \"The outputs are too close!\"\n",
    "\n",
    "# Disable the lora parameters\n",
    "lora_model.disable_lora()\n",
    "\n",
    "# Assert if the values are the same and thus I haven't changed the original model\n",
    "assert np.allclose(model(x).numpy(), lora_model(x).numpy()), \"The outputs are too close!\"\n",
    "print(\"Everything works as expected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
